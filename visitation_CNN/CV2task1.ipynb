{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXn_9vTcTXYA"
      },
      "source": [
        "## Semantic segmentation ##\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY7mhrSibHXn"
      },
      "source": [
        "1. Follow the tutorial at https://github.com/divamgupta/image-segmentation-keras which includes colab work sheet (https://colab.research.google.com/drive/1q_eCYEzKxixpCKH1YDsLnsvgxl92ORcv?usp=sharing). Try the given example."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_ZcxQSg-Q1Qu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha1kdLPIb5zU"
      },
      "source": [
        "2. The github repository contains implementations for various semantic segmentation frameworks. Modify the code to use fully convolutional network (fcn_32 defined in keras_segmentation.models.fcn). Compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "txR8x_mURbLh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJmV4CzceMMg"
      },
      "source": [
        "## Class Activity Mapping ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuH9Np3NePvx"
      },
      "source": [
        "1. Following the tutorial for tf-keras-vis, visualise CAM for the Fashion MNIST model from the last lecture.  https://github.com/keisen/tf-keras-vis/blob/master/docs/examples/attentions.ipynb."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4CTFkdLfg1F",
        "outputId": "56af73a2-1e64-4bb1-d930-dd926eb1485c"
      },
      "source": [
        "# We use Fashion MNIST dataset, which is provided by Keras\n",
        "# The following is the code to load data etc. same as last session\n",
        "\n",
        "# import Keras & Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load image data\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "\n",
        "# Data preparation:\n",
        "#   Map intensities from [0--255] to 0.0--1.0\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\",\n",
        "                        input_shape=[28, 28, 1]),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics = [\"accuracy\"])\n",
        "# reshape: map data to 4D, with the last dimension of 1 channel (grayscale)\n",
        "history = model.fit(x_train.reshape((x_train.shape[0], 28, 28, 1)), y_train, epochs = 60, validation_split=0.1, callbacks=[early_stopping_cb])\n",
        "model.evaluate(x_test.reshape(x_test.shape[0], 28, 28, 1), y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/60\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 1.8318 - accuracy: 0.3220 - val_loss: 0.6854 - val_accuracy: 0.7408\n",
            "Epoch 2/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.8508 - accuracy: 0.6859 - val_loss: 0.5368 - val_accuracy: 0.7907\n",
            "Epoch 3/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.6659 - accuracy: 0.7533 - val_loss: 0.4672 - val_accuracy: 0.8232\n",
            "Epoch 4/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.5861 - accuracy: 0.7889 - val_loss: 0.4420 - val_accuracy: 0.8362\n",
            "Epoch 5/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.5378 - accuracy: 0.8078 - val_loss: 0.4081 - val_accuracy: 0.8492\n",
            "Epoch 6/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.4974 - accuracy: 0.8243 - val_loss: 0.3943 - val_accuracy: 0.8537\n",
            "Epoch 7/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.4685 - accuracy: 0.8359 - val_loss: 0.3839 - val_accuracy: 0.8570\n",
            "Epoch 8/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.4414 - accuracy: 0.8459 - val_loss: 0.3524 - val_accuracy: 0.8657\n",
            "Epoch 9/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.4221 - accuracy: 0.8542 - val_loss: 0.3517 - val_accuracy: 0.8675\n",
            "Epoch 10/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.4033 - accuracy: 0.8562 - val_loss: 0.3351 - val_accuracy: 0.8742\n",
            "Epoch 11/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.3923 - accuracy: 0.8635 - val_loss: 0.3258 - val_accuracy: 0.8803\n",
            "Epoch 12/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.3688 - accuracy: 0.8711 - val_loss: 0.3206 - val_accuracy: 0.8817\n",
            "Epoch 13/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.3724 - accuracy: 0.8699 - val_loss: 0.3160 - val_accuracy: 0.8823\n",
            "Epoch 14/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.3553 - accuracy: 0.8761 - val_loss: 0.3016 - val_accuracy: 0.8853\n",
            "Epoch 15/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.3430 - accuracy: 0.8795 - val_loss: 0.2942 - val_accuracy: 0.8873\n",
            "Epoch 16/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.3387 - accuracy: 0.8813 - val_loss: 0.3077 - val_accuracy: 0.8842\n",
            "Epoch 17/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.3257 - accuracy: 0.8855 - val_loss: 0.3000 - val_accuracy: 0.8935\n",
            "Epoch 18/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.3134 - accuracy: 0.8920 - val_loss: 0.2986 - val_accuracy: 0.8860\n",
            "Epoch 19/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.3113 - accuracy: 0.8934 - val_loss: 0.2822 - val_accuracy: 0.8962\n",
            "Epoch 20/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.3030 - accuracy: 0.8936 - val_loss: 0.3062 - val_accuracy: 0.8922\n",
            "Epoch 21/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.2924 - accuracy: 0.8968 - val_loss: 0.2677 - val_accuracy: 0.8998\n",
            "Epoch 22/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.2868 - accuracy: 0.8997 - val_loss: 0.2818 - val_accuracy: 0.8968\n",
            "Epoch 23/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.2818 - accuracy: 0.9034 - val_loss: 0.2612 - val_accuracy: 0.9062\n",
            "Epoch 24/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.2678 - accuracy: 0.9046 - val_loss: 0.2978 - val_accuracy: 0.8960\n",
            "Epoch 25/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.2617 - accuracy: 0.9103 - val_loss: 0.2639 - val_accuracy: 0.9007\n",
            "Epoch 26/60\n",
            "1688/1688 [==============================] - 11s 6ms/step - loss: 0.2560 - accuracy: 0.9114 - val_loss: 0.2762 - val_accuracy: 0.8987\n",
            "Epoch 27/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.2521 - accuracy: 0.9107 - val_loss: 0.2560 - val_accuracy: 0.9082\n",
            "Epoch 28/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.2421 - accuracy: 0.9151 - val_loss: 0.2602 - val_accuracy: 0.9085\n",
            "Epoch 29/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.2395 - accuracy: 0.9168 - val_loss: 0.2724 - val_accuracy: 0.9087\n",
            "Epoch 30/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.2323 - accuracy: 0.9177 - val_loss: 0.2726 - val_accuracy: 0.9058\n",
            "Epoch 31/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.2248 - accuracy: 0.9201 - val_loss: 0.2721 - val_accuracy: 0.9018\n",
            "Epoch 32/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.2181 - accuracy: 0.9222 - val_loss: 0.2854 - val_accuracy: 0.9070\n",
            "Epoch 33/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.2147 - accuracy: 0.9235 - val_loss: 0.2570 - val_accuracy: 0.9053\n",
            "Epoch 34/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.2073 - accuracy: 0.9289 - val_loss: 0.2578 - val_accuracy: 0.9118\n",
            "Epoch 35/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.2074 - accuracy: 0.9264 - val_loss: 0.2602 - val_accuracy: 0.9120\n",
            "Epoch 36/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.2014 - accuracy: 0.9293 - val_loss: 0.2750 - val_accuracy: 0.9100\n",
            "Epoch 37/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1898 - accuracy: 0.9320 - val_loss: 0.2560 - val_accuracy: 0.9128\n",
            "Epoch 38/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1894 - accuracy: 0.9324 - val_loss: 0.2779 - val_accuracy: 0.9097\n",
            "Epoch 39/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1764 - accuracy: 0.9373 - val_loss: 0.2766 - val_accuracy: 0.9115\n",
            "Epoch 40/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1729 - accuracy: 0.9378 - val_loss: 0.2688 - val_accuracy: 0.9167\n",
            "Epoch 41/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1756 - accuracy: 0.9379 - val_loss: 0.2549 - val_accuracy: 0.9147\n",
            "Epoch 42/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1679 - accuracy: 0.9403 - val_loss: 0.2777 - val_accuracy: 0.9110\n",
            "Epoch 43/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1632 - accuracy: 0.9427 - val_loss: 0.2704 - val_accuracy: 0.9107\n",
            "Epoch 44/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1581 - accuracy: 0.9432 - val_loss: 0.2661 - val_accuracy: 0.9113\n",
            "Epoch 45/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1550 - accuracy: 0.9447 - val_loss: 0.2673 - val_accuracy: 0.9143\n",
            "Epoch 46/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1534 - accuracy: 0.9448 - val_loss: 0.2770 - val_accuracy: 0.9167\n",
            "Epoch 47/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1487 - accuracy: 0.9475 - val_loss: 0.2984 - val_accuracy: 0.9137\n",
            "Epoch 48/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1436 - accuracy: 0.9500 - val_loss: 0.2733 - val_accuracy: 0.9163\n",
            "Epoch 49/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1384 - accuracy: 0.9479 - val_loss: 0.3039 - val_accuracy: 0.9153\n",
            "Epoch 50/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1361 - accuracy: 0.9516 - val_loss: 0.2829 - val_accuracy: 0.9187\n",
            "Epoch 51/60\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.1330 - accuracy: 0.9523 - val_loss: 0.2973 - val_accuracy: 0.9110\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2816 - accuracy: 0.9113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2816052734851837, 0.911300003528595]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "I4_17SLdgc3X",
        "outputId": "d3cfe058-0224-4cdd-a11b-665ec79612ed"
      },
      "source": [
        "# Take the first test as an example\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_test[0, ], cmap = 'gray')\n",
        "plt.show()\n",
        "print(y_test[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmN8CE3Oe3H5"
      },
      "source": [
        "# install/upgrade packages\n",
        "!pip install --upgrade tf-keras-vis tensorflow matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}